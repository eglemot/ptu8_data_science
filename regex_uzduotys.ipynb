{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_format(date):\n",
    "    data_filter = re.compile(r'^(?P<Day>\\d{2}).(?P<Month>\\d{2}).(?P<Year>\\d{4})')\n",
    "    filter_result = data_filter.search(date)\n",
    "    if filter_result:\n",
    "        return data_filter.sub('\\g<3> \\g<2> \\g<1>', date)\n",
    "    else: \n",
    "        print(\"data not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1997 02 05'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_format(\"05.02.1997\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Workshop & Tutorial proposals: November 21, 2019\n",
    "Notification of acceptance: December 1, 2019\n",
    "Workshop & Tutorial websites online: December 18, 2019\n",
    "Workshop papers: February 28, 2020\n",
    "Workshop paper notifications: March 27, 2020\n",
    "Workshop paper camera-ready versions: April 10, 2020\n",
    "Tutorial material due (online): April 10, 2020'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['November 21, 2019',\n",
       " 'December 1, 2019',\n",
       " 'December 18, 2019',\n",
       " 'February 28, 2020',\n",
       " 'March 27, 2020',\n",
       " 'April 10, 2020',\n",
       " 'April 10, 2020']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_data = re.compile(r'\\w{3,9} \\d{1,2}, \\d{4}')\n",
    "visus = find_data.findall(text)\n",
    "visus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Event: Workshop & Tutorial proposals\n",
      "Date: November 21, 2019\n",
      "2.\n",
      "Event: Notification of acceptance\n",
      "Date: December 1, 2019\n",
      "3.\n",
      "Event: Workshop & Tutorial websites online\n",
      "Date: December 18, 2019\n",
      "4.\n",
      "Event: Workshop papers\n",
      "Date: February 28, 2020\n",
      "5.\n",
      "Event: Workshop paper notifications\n",
      "Date: March 27, 2020\n",
      "6.\n",
      "Event: Workshop paper camera-ready versions\n",
      "Date: April 10, 2020\n",
      "7.\n",
      "Event: Tutorial material due (online)\n",
      "Date: April 10, 2020\n"
     ]
    }
   ],
   "source": [
    "find_everything = re.compile(r'^(.+?(?=:)): (\\w{3,9} \\d{1,2}, \\d{4})', re.MULTILINE)\n",
    "filter_result = find_everything.findall(text)\n",
    "for nr, line in enumerate(filter_result, 1):\n",
    "    event, date = line\n",
    "    print(f'{nr}.\\nEvent: {event}\\nDate: {date}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def censorhip(text, *args):\n",
    "    pattern = re.compile(r'([a-ząčęėįšųūž])([a-ząčęėįšųūž]+)([a-ząčęėįšųūž])')\n",
    "    for word in args:\n",
    "        grouped = pattern.search(word)\n",
    "        censored_part = len(grouped.group(2)) * \"*\"\n",
    "        censored_word = pattern.sub(f'\\g<1>{censored_part}\\g<3>', word)\n",
    "        text = text.replace(word, censored_word)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baisūs žodžiai, tokie kaip k*****a, ž****s..\n"
     ]
    }
   ],
   "source": [
    "censorhip('baisūs žodžiai, tokie kaip kvaraba, žaltys..', 'kvaraba', 'žaltys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['youtube.com',\n",
       " 'wikipedia.org',\n",
       " 'facebook.com',\n",
       " 'twitter.com',\n",
       " 'amazon.com',\n",
       " 'imdb.com',\n",
       " 'reddit.com',\n",
       " 'pinterest.com',\n",
       " 'ebay.com',\n",
       " 'tripadvisor.com',\n",
       " 'craigslist.org',\n",
       " 'walmart.com',\n",
       " 'instagram.com',\n",
       " 'google.com',\n",
       " 'nytimes.com',\n",
       " 'apple.com',\n",
       " 'linkedin.com',\n",
       " 'indeed.com',\n",
       " 'google.com',\n",
       " 'espn.com',\n",
       " 'webmd.com',\n",
       " 'cnn.com',\n",
       " 'homedepot.com',\n",
       " 'etsy.com',\n",
       " 'netflix.com',\n",
       " 'quora.com',\n",
       " 'microsoft.com',\n",
       " 'target.com',\n",
       " 'webster.com',\n",
       " 'forbes.com',\n",
       " 'mapquest.com',\n",
       " 'gamepedia.com',\n",
       " 'yahoo.com',\n",
       " 'healthline.com',\n",
       " 'foxnews.com',\n",
       " 'allrecipes.com',\n",
       " 'quizlet.com',\n",
       " 'weather.com',\n",
       " 'bestbuy.com',\n",
       " 'urbandictionary.com',\n",
       " 'mayoclinic.org',\n",
       " 'aol.com',\n",
       " 'genius.com',\n",
       " 'zillow.com',\n",
       " 'usatoday.com',\n",
       " 'glassdoor.com',\n",
       " 'msn.com',\n",
       " 'rottentomatoes.com',\n",
       " 'lowes.com',\n",
       " 'dictionary.com',\n",
       " 'businessinsider.com',\n",
       " 'usnews.com',\n",
       " 'medicalnewstoday.com',\n",
       " 'britannica.com',\n",
       " 'washingtonpost.com',\n",
       " 'usps.com',\n",
       " 'yahoo.com',\n",
       " 'yellowpages.com',\n",
       " 'chase.com',\n",
       " 'retailmenot.com',\n",
       " 'accuweather.com',\n",
       " 'wayfair.com',\n",
       " 'go.com',\n",
       " 'live.com',\n",
       " 'yahoo.com',\n",
       " 'steamcommunity.com',\n",
       " 'xfinity.com',\n",
       " 'cnet.com',\n",
       " 'ign.com',\n",
       " 'steampowered.com',\n",
       " 'macys.com',\n",
       " 'wikihow.com',\n",
       " 'yahoo.com',\n",
       " 'wiktionary.org',\n",
       " 'cbssports.com',\n",
       " 'cnbc.com',\n",
       " 'bankofamerica.com',\n",
       " 'expedia.com',\n",
       " 'wellsfargo.com',\n",
       " 'groupon.com',\n",
       " 'khanacademy.org',\n",
       " 'theguardian.com',\n",
       " 'paypal.com',\n",
       " 'spotify.com',\n",
       " 'att.com',\n",
       " 'nfl.com',\n",
       " 'realtor.com',\n",
       " 'goodreads.com',\n",
       " 'office.com',\n",
       " 'mlb.com',\n",
       " 'foodnetwork.com',\n",
       " 'bbc.com',\n",
       " 'apartments.com',\n",
       " 'npr.org',\n",
       " 'wowhead.com']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('most_visited.html.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "pages = re.compile(r'\\w*.org|\\w*.com')\n",
    "find = pages.findall(text)\n",
    "find\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
